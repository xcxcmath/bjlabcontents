<h2>
    퍼셉트론의 정의
</h2>
<p>
    &nbsp;프랑크 로젠블라트<sup>Frank Rosenblatt</sup>가 1957년에 제안한 알고리즘인 퍼셉트론<sup>Perceptron</sup>에 대해 살펴보자.
    딥러닝이 아니더라도 퍼셉트론은 머신러닝 분야에서 매우 중요한 역할을 해왔고, 앞으로 설명할 유닛이라는 개념의 기원이기도 하다.
    비록 딥러닝이 할 수 있는 일보다는 적을지 모르지만 그를 이해하는 것만으로도 딥러닝을 배우는 데에 커다란 발판이 될 것이다.
</p>
<p>
    &nbsp;퍼셉트론은 여러 개의 입력에 대한 하나의 출력을 정의하는 구조체이다. 이름에서 보듯 뉴런<sup>Neuron</sup>처럼 행동하기 때문에
    실제 뉴런 처럼 일정 임계값을 넘는 입력이 들어오면 1을 출력하고, 아니면 0을 출력한다. 여기서 "임계값을 넘는 입력"은 무엇을 뜻하는가?
    분명 입력은 여러 개이기 때문에 그 입력값들을 대표하는 하나의 입력이 존재한다는 뜻이다. 퍼셉트론은 그 대표 입력을 다음과 같이 정한다.
</p>
<p>
    &nbsp;어떤 퍼셉트론에 대한 입력이 아래 n개의 값으로 들어온다고 하자.
</p>
<div lang="latex">
    x_1, x_2, \cdots ,x_n
</div>
<p>
    각각의 입력에는 가중치<sup>Weight</sup>가 존재하여 퍼셉트론에 입력이 들어갈때 해당되는 가중치가 곱해진다.
</p>
<div lang="latex">
    w_1 x_1, w_2 x_2, \cdots , w_n x_n
</div>
<p>
    이제 이들을 모두 더하면 퍼셉트론에 대한 대표 입력값이 된다. 여기서는 그 대표 입력을 u라고 표기하도록 하겠다.
</p>
<div lang="latex">
    u = \sum _{k=1} ^n w_k x_k
</div>
<p>
    &nbsp;이제 이 퍼셉트론에 대한 출력을 정의하자. 이 입력값이 임계값을 넘으면 1을 출력하므로 출력값을 y, 임계값을 그리스 문자 세타로 표기하면 아래와 같다.
</p>
<div lang="latex">
    y = \left\{ \begin{matrix}
    0 & (u \leq \theta) \\
    1 & (u > \theta)
    \end{matrix}
</div>
<p>
    이렇게 출력이 0과 1 둘중 하나라는 것을 생각하면, 마치 회로상의 전류처럼 신호가 흐른다, 고 표현할 수 있을 것 같다.
</p>
<p>
    &nbsp;때때로 임계값 대신 편향<sup>Bias</sup>이라는 개념을 도입하기도 한다. 편향은 어떤 상황에서든
    u에 고정적으로 더해지는 값으로 마치 사람의 편견처럼 작용한다. 편견이라 하면 조금 부정적인 어감이 있지만 퍼셉트론의 행동에
    중요한 역할을 한다.
</p>
<div lang="latex">
    u = b + \sum _{k=1} ^n w_k x_k
</div>
<p>
    이렇게 되면 임계값을 단순히 0으로 설정해도 일반성을 잃지 않는다.
</p>
<div lang="latex">
    y = \left\{ \begin{matrix}
    0 & (u \leq 0) \\
    1 & (u > 0)
    \end{matrix}
</div>
<p>
    실제 딥러닝에서 사용하는 표현은 임계치보다는 편향이 더 많기에 여기서도 편향을 사용할 것이다.
</p>
<h2>
    퍼셉트론과 행렬
</h2>
<p>
    &nbsp;앞에서 설명을 했겠지만 퍼셉트론의 입력처럼 여러 개의 수치를 다룰 때에는 행렬을 이용하는 것이 편하고 빠르다. 행렬을 이 퍼셉트론의 입력에 적용을 해보자.
    우선 입력 n개를 아래 행렬 처럼 표현할 수 있다.
</p>
<div lang="latex">
    \mathbf{x}=\begin{pmatrix}
    x_1\\
    x_2\\
    \vdots \\
    x_n
    \end{pmatrix}
</div>
<p>
    가중치도 마찬가지로 아래처럼 표현할 수 있다.
</p>
<div lang="latex">
    \mathbf{w}=\begin{pmatrix}
    w_1\\
    w_2\\
    \vdots \\
    w_n
    \end{pmatrix}
</div>
<p>
    전치 행렬을 적용해서 아래 수식으로 표현하면 시그마를 쓰는 것 보다 훨씬 간결한 것을 볼 수 있다.
</p>
<div lang="latex">
    u = \mathbf{w}^{\top }\mathbf{x} + b
</div>
<h2>
    퍼셉트론의 예
</h2>
<p>
    &nbsp;이제 이 퍼셉트론을 적용해보자. 가장 간단한 형태로는 입력이 두 개뿐인 논리 회로상의 게이트를 예로 들 수 있다.
    NAND 게이트를 퍼셉트론으로 구현하기 위해 적절한 가중치, 편견을 설정해야 한다. 좌표 평면 상의 그래프를 이용해서
    값을 설정할 수 있는데 과정은 생략하고 답만 쓰면 아래와 같다.
</p>
<div lang="latex">
    \mathbf{w}=\begin{pmatrix}
    -0.5\\
    -0.5
    \end{pmatrix}, b = 0.7
</div>
<p>
    위 값을 그대로 프로그래밍 시키면 아래처럼 표현할 수 있다.
</p>
<pre class="brush: cpp">
bool NAND_perceptron(const bool x1, const bool x2)
{
    matrix x(2, 1);
    x(0, 0) = static_cast&lt;double&gt;(x1); x(1, 0) = static_cast&lt;double&gt;(x2);

    matrix w(2, 1);
    w(0, 0) = -0.5; w(1, 0) = -0.5;

    double b = 0.7;

    double u = (w.transpose() * x)(0, 0) + b;

    return u > 0.;
}
</pre>
<p class="tip">
    의도에 맞는 가중치와 편향의 값은 무수히 많다. 편향이 꼭 0.7이 아니라 0.71도 되고 0.9999도 된다. 원하는 정답만 나온다면 어떤 값이든지 상관이 없다.
</p>
<h2>
    다층 퍼셉트론
</h2>
<p>
    &nbsp;아쉽게도 퍼셉트론은 만능이 아니다. 논리 게이트만 봐도 XOR게이트는 하나의 퍼셉트론으로는 절대 구현할 수 없다.
    왜 그럴까? 입력 x들로부터 u를 계산하는 과정에는 오로지 선형 변환만 존재한다. 즉 "중간에" 비선형적인 변환이 필요한 XOR 계산은 퍼셉트론으로
    구현할 수 없다. 이 한계를 퍼셉트론을 여러개 쌓아서 해결한 것이 다층 퍼셉트론<sup>Multi-layer Perceptron</sup>이다. u에서 y를 게산하는 과정은
    비선형이기 때문에 출력을 다시 다른 퍼셉트론의 입력으로 생각한다면 비선형 변환을 구현할 수 있다. NAND와 OR 게이트는 하나의 퍼셉트론으로 구현이 가능하고,
    XOR는 이들의 조합으로 구현이 가능한데 어떻게 조합해야 하는지는 직접 생각해 보길 바란다.
</p>
<h2>
    퍼셉트론과 신경망
</h2>
<p>
    &nbsp;다층 퍼셉트론까지 만들었어도 여전히 그에게는 단점이 존재한다. 가중치와 편향을 일일이 사람이 계산해야 하기 때문이다. 그 원인은
    바로 u에서 y로의 변환에서 존재한다. 해당 식의 그래프를 그려보면 u=0에서 불연속적인 값의 변화 말고는 평탄한 직선이 만들어지기에 u가 어떤 값이었는지 역추적이 불가능하다.
    이 역추적 과정은 앞으로 배울 학습이라는 과정의 중요한 성질이다. 퍼셉트론은 이 학습을 하지 못한다.
</p>
<p>
    &nbsp;이를 해결하기 위해선 출력값을 계산하는 다른 방식이 필요하다. 어떤 방식인지 궁금하지 않은가?
</p>
