<h2>
    왜 수학을 배워야 하나?
</h2>
<p>
    &nbsp;프로그래밍 언어 문법을 넘어서 본격적으로 컴퓨팅 사고를 요하는 내용을 접해본 사람은 이미
    그 이유를 알 것이다. 특히나 인공지능이라는 분야에서는 더더욱. 딥러닝을 쉽게 풀어 썼다고 자신하는
    책들도 현 고등학교 수학 지식을 넘어서야 조금 읽히는게 가능할 정도다. (아니라면 그건 원리를 설명해놓지 않았을 가능성이 농후하다.)
    그리고 그는 보통 수없이 반복되는 수식의 향연을 수반한다.
</p>
<p>
    &nbsp;그러나 필요한 기초지식이 어디까지인지 국제적으로 합의된 적은 없다.
    관심있는 분야에 따라 다르다고 하는게 정확할지도. 내 생각엔 대부분 행렬의
    기본 연산, 편미분, 미분방정식을 좀 다룰 줄 안다면 충분하다.
    그 정도만 설명해놓은 책이 많기 때문이다. 그러나 자기부호화기나 중급 최적화를
    배울 정도로 조금만 진도를 나가도 선형 대수학 과목을 대학에서 수강해야 직관적으로 이해할 수 있다.
    그렇지 않으면 그냥 암기 과목이 되어버린다.
</p>
<p>
    &nbsp;그 많은 내용을 한 글에 몰아서 때우기 보다는 나보다 글쓰기 실력이 좋은 몇몇 블로거의 글을
    찾아 읽는 것이 더 이득이기 때문에, 다른 책에서는 이미 독자가 알고 있다고 생각하는
    고등학교 수준 이상의 수학 내용을 보충해주는 정도로 설명하는 것이 옳다고 생각한다. 대표적으로
    방금 언급했던 편미분, 미분방정식, 행렬 연산이 그것이다. 이들의 기본 정리들을 증명하진 않을 것이다.
    배보다 배꼽이 더 커질 수 있다. 그저 이런 내용을 알아야 하구나 하고 다른 곳에서 심화 내용을 보기를.
</p>
<h2>
    편미분
</h2>
<p>
    &nbsp;함수는 단일 변수를 가질 수도 있고 두 개 이상의 변수를 가질 수도 있다.
    하나의 변수만 가진 함수 미분한다고 생각해보자.
</p>
<div lang="latex">
    f \left( x \right) \rightarrow {df \over dx}
</div>
<p>
    이 함수의 도함수를 구할 때 필요한 변화율은 x와 f(x) 두 가지이다. 함수값은 순수히 함수의 변수에 의존하므로
    사실상 필요한 값의 개수는 하나이다. 이는 이변수 이상의 함수에서도 적용된다. 아래와 같은 경우 변수가 2개이므로 원하는 변수에 따라 다른 변화율을
    구할 수 있다.
</p>
<div lang="latex">
    f \left( x,y \right) \rightarrow {\partial f \over \partial x}, {\partial f \over \partial y}
</div>
<p>
    하나의 변수로 미분할 때에는 다른 모든 변수는 상수 취급하여 단일 변수 함수를 미분하듯이 하면 된다. 이를 수학자들은 원래의 미분이라는 용어와 별개로
    편미분이라는 이름을 붙여주었다.
</p>
<p>
    &nbsp;거의 모든 면에서 편미분은 미분과 닮은 점이 많지만 주의해야 할 점이 하나 있다. 연쇄 법칙<sup>Chain Rule</sup>이 그것인데 길게 적진 않을 테니 아래
    식으로 모든 설명을 생략하도록 하겠다.
</p>
<div lang="latex">
    {df(x(t)) \over dt} = {df \over dx}{dx \over dt}
</div>
<div lang="latex">
    {\partial f(x_1(t), \cdots , x_n(t)) \over \partial t} = \sum_{k=1}^{n}{\partial f \over \partial x_k}{\partial x_k \over \partial t}
</div>
<h2>
    미분방정식
</h2>
<p>
    &nbsp;기초적인 다항식, 분수, 로그함수를 미분하는 일은 어렵지 않다. 그리고 이런 함수의 도함수만으로 다시 원래 함수를 구하는 수많은 기법들이 개발되었다.
    우리들이 적분이라고 익히 들었던 것이 그것이다. 그렇지만 적분<sup>積分</sup>은 그 한자 뜻에서 보듯이 본래 주어진 함수가 나타내는 영역의 길이, 넓이, 부피를
    구하기 위해 미소부분을 일일이 쌓아 올리는 방식을 아름답게 표현한 것이고, 그것이 어쩌다 미분과 반대방향이라는 게 밝혀졌을 뿐이다.
    따라서 원래 함수를 "구한다"라는 표현에 맞게 방정식이라는 이름을 달아서 미분방정식으로 불리는 것이 일반적이다.
</p>
<p>
    &nbsp;딥러닝에서 요구하는 아주 기초적인 미분방정식을 푸는 방법은 적분과 다르지 않다.
</p>
<div lang="latex">
    {dy \over dx} = r(x)
</div>
<div lang="latex">
    y = R(x) + C
</div>
<p>
    더 복잡한 미분방정식은 내용이 길어질 것 같아 필요시 써놓도록 하겠다.
</p>
<h2>
    행렬
</h2>
<p>
    &nbsp;만약 고등학교 수학에서 진도를 끝냈다면, 벡터를 (x, y, z)처럼 일렬로 스칼라를 넣어놓은 구조체라고 보기 쉽다.
    그리고 그는 좌표평면, 또는 좌표공간에서 방향성을 가지고 있어 아래와 같은 표기를 하곤 한다.
</p>
<div lang="latex">
    \overrightarrow{v} = (x, y)
</div>
<p>
    그러나 선형대수학, 딥러닝에서 사용하는 벡터는 약간 다른 표기를 사용한다. 기호를 저렇게 위에 화살표를 쓰지 않고 단순히
    볼드체로 표기한다. 또한 보통 열벡터<sup>Column Vector</sup>라고 하여 가로로 원소를 표기하지 않고 세로로 쓴다.
</p>
<div lang="latex">
    \mathbf{v} = \left( \begin{matrix} x \\ y \end{matrix} \right)
</div>
<p>
    행렬은 이 열벡터, 또는 행벡터<sup>Row Vector</sup>들의 조합으로 볼 수 있다. 행렬의 원소는 행, 열 순으로 기호의 아래첨자로 표기한다.
</p>
<div lang="latex">
    \mathbf{W} = \left( \begin{matrix} w_{11} &amp; w_{12} \\ w_{21} &amp; w_{22} \end{matrix} \right)
</div>
<p>
    &nbsp;행렬 및 벡터간의 연산은 인터넷에서 쉽게 찾아볼 수 있다. 다만 한가지, 아다마르 곱<sup>Hadamard Product</sup>은
    다른 행렬의 곱셈에 비해 덜 언급이 되어있다. 이 곱셈은 동일한 크기의 행렬 둘에 대해 같은 위치에 있는 원소끼리
    곱하는 연산이다.
</p>
<div lang="latex">
    \mathbf{A} \bigodot \mathbf{B} = \left( \begin{matrix} a_{11}b_{11} &amp; a_{12}b_{12} \\ a_{21}b_{21} &amp; a_{22}b_{22} \end{matrix} \right)
</div>
<h2>
    함수의 입력
</h2>
<p>
    &nbsp;어떤 데이터를 잘 표현하는 대강의 포물선을 찾기 위해 아래 함수를 정의했다고 하자.
</p>
<div lang="latex">
    f(x) = ax^2 + bx + c
</div>
<p>
    이 함수의 입력<sup>Input</sup>이 무엇이냐 하고 묻는다면 당연히 x라고 답할 것이다. 어쨌거나 출력을 얻어내기 위해서는 x의 입력이
    필연적이기 때문이다. 하지만 저 함수의 a, b, c값을 조정해야 한다면, 그들도 함수값에 영향을 미치므로 "x와 달리 a, b, c는 입력이 아니다"라고도 할 수 없다.
    또 한편으로 저 함수를 활용하려는 사용자 입장에서는, a~c값에 상관없이 입력 x에 관한 출력 f(x)만을 얻고 싶어 할 것이다. 즉 x와 a, b, c는 똑같이 입력이긴 하지만
    서로 성격이 다른 입력이라는 것이다. 따라서 a~c는 x와 별개로 함수의 파라미터<sup>Parameter</sup>라고 부르며, 파라미터가 필요한 경우 아래와 같이 함수를 나타낸다.
</p>
<div lang="latex">
    f(x;a, b, c) = ax^2 + bx + c
</div>
<p class="tip">
    사실 저 파라미터의 정의는 신경망을 기술할 때 주로 쓰이는 설명이다. 명확하고 통일된 설명을 찾지 못했기에, 딥러닝을 배우려는 취지에 맞는 정의를 얼추 적어 넣었다.
</p>
